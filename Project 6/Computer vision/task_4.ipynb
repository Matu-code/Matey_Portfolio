{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "from tensorflow import keras\n",
    "from patchify import patchify, unpatchify\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder =  r'C:\\Users\\mened\\OneDrive\\Documents\\2023-24b-fai2-adsai-MateyNedyalkov221889\\1. Computer Vision\\DataLab tasks\\Dataset\\train'\n",
    "test_folder = r'C:\\Users\\mened\\OneDrive\\Documents\\2023-24b-fai2-adsai-MateyNedyalkov221889\\1. Computer Vision\\DataLab tasks\\Dataset\\test'\n",
    "masks_folder = r'C:\\Users\\mened\\OneDrive\\Documents\\2023-24b-fai2-adsai-MateyNedyalkov221889\\1. Computer Vision\\DataLab tasks\\Masks'\n",
    "\n",
    "train_masks_folder = r'C:\\Users\\mened\\OneDrive\\Documents\\2023-24b-fai2-adsai-MateyNedyalkov221889\\1. Computer Vision\\DataLab tasks\\train_masks'\n",
    "test_masks_folder = r'C:\\Users\\mened\\OneDrive\\Documents\\2023-24b-fai2-adsai-MateyNedyalkov221889\\1. Computer Vision\\DataLab tasks\\test_masks'\n",
    "images_with_no_masks_folder = r'C:\\Users\\mened\\OneDrive\\Documents\\2023-24b-fai2-adsai-MateyNedyalkov221889\\1. Computer Vision\\DataLab tasks\\images_with_no_masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, type):\n",
    "\n",
    "    file_list = sorted(os.listdir(path))\n",
    "    data = []\n",
    "\n",
    "    count = 0\n",
    "    combined_mask = None\n",
    "    value = 1\n",
    "\n",
    "    for filename in file_list:\n",
    "        if filename.endswith(type):\n",
    "            input_image_path = os.path.join(path, filename)\n",
    "            if type == '.tif':\n",
    "                input_image = cv2.imread(input_image_path, 0)\n",
    "                \n",
    "                if combined_mask is None:\n",
    "                    combined_mask = np.zeros_like(input_image)\n",
    "\n",
    "                combined_mask[input_image == 1] = value \n",
    "                count += 1\n",
    "                value += 1\n",
    "                \n",
    "                if count % 4 == 0:\n",
    "\n",
    "                    data.append(combined_mask)\n",
    "                    combined_mask = None\n",
    "                    value = 1\n",
    "\n",
    "            else:\n",
    "                input_image = cv2.imread(input_image_path, 0)\n",
    "                data.append(input_image)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaying_images(data, number_of_images=5): \n",
    "    \n",
    "    for idx, img in enumerate(data):\n",
    "        if idx < number_of_images:\n",
    "            plt.figure()\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            plt.axis('off')  \n",
    "            plt.show()\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_masks(output_train_folder, output_test_folder, output_no_mask_folder, input_train_folder, input_test_folder, masks_folder, prefixes_to_remove):\n",
    "    \n",
    "    os.makedirs(output_train_folder, exist_ok=True)\n",
    "    os.makedirs(output_test_folder, exist_ok=True)\n",
    "    os.makedirs(output_no_mask_folder, exist_ok=True)\n",
    "\n",
    "    # List all images in the train and test folders\n",
    "    train_images = os.listdir(input_train_folder)\n",
    "    test_images = os.listdir(input_test_folder)\n",
    "\n",
    "    # Create a set to keep track of matched images\n",
    "    matched_images = set()\n",
    "\n",
    "    # Iterate through the masks and move them to the corresponding train or test folder\n",
    "    for mask in os.listdir(masks_folder):\n",
    "        mask_name, mask_extension = os.path.splitext(mask)\n",
    "        \n",
    "        # Remove each prefix from the mask name\n",
    "        for prefix in prefixes_to_remove:\n",
    "            mask_name = mask_name.replace(prefix, '')\n",
    "        \n",
    "        # Initialize lists to store matches for train and test images\n",
    "        train_matches = [img for img in train_images if f\"{mask_name}.png\" in img]\n",
    "        test_matches = [img for img in test_images if f\"{mask_name}.png\" in img]\n",
    "        \n",
    "        # Move the mask to the corresponding train and test folders\n",
    "        for match in train_matches:\n",
    "            src_path = os.path.join(masks_folder, mask)\n",
    "            dest_path = os.path.join(output_train_folder, mask)\n",
    "            shutil.copy(src_path, dest_path)\n",
    "            matched_images.add(match)\n",
    "        \n",
    "        for match in test_matches:\n",
    "            src_path = os.path.join(masks_folder, mask)\n",
    "            dest_path = os.path.join(output_test_folder, mask)\n",
    "            shutil.copy(src_path, dest_path)\n",
    "            matched_images.add(match)\n",
    "\n",
    "        # Print a warning if the modified mask name doesn't match any image (optional)\n",
    "        if not train_matches and not test_matches:\n",
    "            print(f\"Warning: Mask '{mask_name}' does not match any image.\")\n",
    "\n",
    "    # Move unmatched images to the output_unmatched_folder\n",
    "    for img in set(train_images + test_images) - matched_images:\n",
    "        src_path = os.path.join(input_train_folder if img in train_images else input_test_folder, img)\n",
    "        dest_path = os.path.join(output_no_mask_folder, img)\n",
    "        shutil.move(src_path, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padder(image, patch_size):\n",
    "\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]\n",
    "    height_padding = ((h // patch_size) + 1) * patch_size - h\n",
    "    width_padding = ((w // patch_size) + 1) * patch_size - w\n",
    "\n",
    "    top_padding = int(height_padding/2)\n",
    "    bottom_padding = height_padding - top_padding\n",
    "\n",
    "    left_padding = int(width_padding/2)\n",
    "    right_padding = width_padding - left_padding\n",
    "\n",
    "    padded_image = cv2.copyMakeBorder(image, top_padding, bottom_padding, left_padding, right_padding, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_image(input_im):\n",
    "\n",
    "    if len(input_im.shape) == 3 and input_im.shape[2] == 3:\n",
    "        im_gray = cv2.cvtColor(input_im, cv2.COLOR_BGR2GRAY)\n",
    "    elif len(input_im.shape) == 2:\n",
    "        # If the input image is already grayscale, no need to convert\n",
    "        im_gray = input_im\n",
    "    else:\n",
    "        # Handle other cases (e.g., images with more than 3 channels)\n",
    "        raise ValueError(\"Unsupported number of channels in input image\")\n",
    "\n",
    "    kernel = np.ones((50, 50), dtype=\"uint8\")\n",
    "\n",
    "    im_e = cv2.dilate(im_gray, kernel, iterations=1)\n",
    "    im_closing = cv2.erode(im_e, kernel, iterations=1)\n",
    "\n",
    "    th, output_im = cv2.threshold(im_closing, 160, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    retval, labels, stats, centroids = cv2.connectedComponentsWithStats(output_im)\n",
    "\n",
    "    area_of_interest = None\n",
    "    largest_area = 0\n",
    "\n",
    "    for i in range(1, len(stats)):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > largest_area:\n",
    "            largest_area = area\n",
    "            area_of_interest = (x, y, w, h)\n",
    "\n",
    "    x, y, w, h = area_of_interest\n",
    "\n",
    "    image = cv2.rectangle(input_im, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "    roi = input_im[y:y+h, x:x+w]\n",
    "    return roi, y, h, x, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_data(images, masks, patch_size, scaling_factor):\n",
    "\n",
    "#     images_list = []\n",
    "#     masks_list = []\n",
    "\n",
    "#     for image in images:\n",
    "#         image = roi_image(image)\n",
    "#         image = padder(image, patch_size)\n",
    "#         if scaling_factor != 1:\n",
    "#             image = cv2.resize(image, (0, 0), fx=scaling_factor, fy=scaling_factor)\n",
    "#         patches = patchify(image, (patch_size, patch_size), step=patch_size)\n",
    "#         patches = patches.reshape(-1, patch_size, patch_size, 1)\n",
    "#         images_list.append(patches)\n",
    "\n",
    "#     for mask in masks:\n",
    "#         mask = padder(mask, patch_size)\n",
    "#         if scaling_factor != 1:\n",
    "#             mask = cv2.resize(mask, (0, 0), fx=scaling_factor, fy=scaling_factor)\n",
    "#         patches = patchify(mask, (patch_size, patch_size), step=patch_size)\n",
    "#         patches = patches.reshape(-1, patch_size, patch_size, 1)\n",
    "#         masks_list.append(patches)\n",
    "\n",
    "#     X = np.array(images_list)\n",
    "#     y = np.array(masks_list)\n",
    "\n",
    "#     X = X.reshape(-1, patch_size, patch_size, 1)\n",
    "#     y = y.reshape(-1, patch_size, patch_size, 1)\n",
    "\n",
    "#     X = X/255\n",
    "\n",
    "#     return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(images, masks, patch_size, scaling_factor):\n",
    "    images_list = []\n",
    "    masks_list = []\n",
    "\n",
    "    for image, mask in zip(images, masks):\n",
    "        # Apply ROI to both image and mask\n",
    "\n",
    "        _, y, h, x, w = roi_image(image)\n",
    "        \n",
    "        image_roi = image[y:y+h, x:x+w]\n",
    "        mask_roi = mask[y:y+h, x:x+w]\n",
    "\n",
    "        # Perform additional processing as needed\n",
    "        image_roi = padder(image_roi, patch_size)\n",
    "        mask_roi = padder(mask_roi, patch_size)\n",
    "\n",
    "        if scaling_factor != 1:\n",
    "            image_roi = cv2.resize(image_roi, (0, 0), fx=scaling_factor, fy=scaling_factor)\n",
    "            mask_roi = cv2.resize(mask_roi, (0, 0), fx=scaling_factor, fy=scaling_factor)\n",
    "\n",
    "        # Patchify the processed image and mask\n",
    "        image_patches = patchify(image_roi, (patch_size, patch_size), step=patch_size)\n",
    "        mask_patches = patchify(mask_roi, (patch_size, patch_size), step=patch_size)\n",
    "\n",
    "        # Reshape the patches\n",
    "        image_patches = image_patches.reshape(-1, patch_size, patch_size, 1)\n",
    "        mask_patches = mask_patches.reshape(-1, patch_size, patch_size, 1)\n",
    "\n",
    "        images_list.append(image_patches)\n",
    "        masks_list.append(mask_patches)\n",
    "\n",
    "    X = np.array(images_list)\n",
    "    y = np.array(masks_list)\n",
    "\n",
    "    # Reshape the arrays\n",
    "    X = X.reshape(-1, patch_size, patch_size, 1)\n",
    "    y = y.reshape(-1, patch_size, patch_size, 1)\n",
    "\n",
    "    # Normalize the image data\n",
    "    X = X / 255.0\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoding(data):\n",
    "\n",
    "    n, h, w, c = data.shape\n",
    "    le = LabelEncoder()\n",
    "    data_reshaped = data.reshape(-1, 1)\n",
    "    data_reshaped_encoded = le.fit_transform(data_reshaped)\n",
    "    data_encoded_original_shape = data_reshaped_encoded.reshape(n, h, w, c)\n",
    "\n",
    "    return data_encoded_original_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_categorical(data, num_classes):\n",
    "    \n",
    "    train_masks_cat = to_categorical(data, num_classes=num_classes)\n",
    "    y_train_cat = train_masks_cat.reshape((data.shape[0], data.shape[1], data.shape[2], num_classes))\n",
    "\n",
    "    return y_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = TP / (Positives+K.epsilon())\n",
    "        return recall\n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    def f(y_true, y_pred):\n",
    "        intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "        total = K.sum(K.square(y_true),[1,2,3]) + K.sum(K.square(y_pred),[1,2,3])\n",
    "        union = total - intersection\n",
    "        return (intersection + K.epsilon()) / (union + K.epsilon())\n",
    "    return K.mean(f(y_true, y_pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_unet_model(n_classes, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS):\n",
    "# Build the model\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    s = inputs\n",
    "\n",
    "    # Contraction path\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "     \n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "     \n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "     \n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    \n",
    "    # Expansive path \n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "     \n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "     \n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "     \n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "     \n",
    "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
    "     \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1, iou])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_plot(H, title):    \n",
    "    plt.plot(H.history['loss'], label='loss')\n",
    "    plt.plot(H.history['val_loss'], label='val_loss')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plot = plt.show()\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_plot(H, title):\n",
    "    plt.plot(H.history['accuracy'], label='accuracy')\n",
    "    plt.plot(H.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    plot = plt.show()\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefixes = ['_shoot_mask', '_seed_mask', '_root_mask', '_occluded', '_seeds_mask', '_occluded_mask', '_mask']\n",
    "\n",
    "# matching_masks(train_masks_folder, test_masks_folder, images_with_no_masks_folder, train_folder, test_folder, masks_folder, prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = load_data(train_folder, type='.png')\n",
    "images_test = load_data(test_folder, type='.png')\n",
    "masks_train = load_data(train_masks_folder, type='.tif')\n",
    "masks_test = load_data(test_masks_folder, type='.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 128\n",
    "scaling_factor = 0.5\n",
    "\n",
    "X_train, y_train = preprocess_data(images_train, masks_train, patch_size, scaling_factor)\n",
    "X_test, y_test = preprocess_data(images_test, masks_test, patch_size, scaling_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 5\n",
    "\n",
    "y_train = labels_to_categorical(y_train, n_classes)\n",
    "y_test = labels_to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train images:  (7502, 128, 128, 1)\n",
      "Shape of test images:  (2541, 128, 128, 1)\n",
      "Shape of train masks:  (7502, 128, 128, 5)\n",
      "Shape of test masks:  (2541, 128, 128, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of train images: \", X_train.shape)\n",
    "print(f\"Shape of test images: \", X_test.shape)\n",
    "print(f\"Shape of train masks: \", y_train.shape)\n",
    "print(f\"Shape of test masks: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 128, 128, 16  160         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128, 128, 16  0           ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 128, 128, 16  2320        ['dropout[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 64, 16)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 64, 64, 32)   4640        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64, 64, 32)   0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 64, 64, 32)   9248        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 32)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 64)   18496       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 32, 32, 64)   0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 64)   36928       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 64)  0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 128)  73856       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 16, 16, 128)  0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 128)  147584      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 128)   0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 8, 8, 256)    295168      ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 8, 8, 256)    0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 8, 256)    590080      ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 16, 16, 128)  131200     ['conv2d_9[0][0]']               \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 16, 16, 256)  0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 128)  295040      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 16, 16, 128)  0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 128)  147584      ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 32, 32, 64)  32832       ['conv2d_11[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 32, 32, 128)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 32, 32, 64)   73792       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 32, 32, 64)   0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 32, 32, 64)   36928       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 64, 64, 32)  8224        ['conv2d_13[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 64, 64, 64)   0           ['conv2d_transpose_2[0][0]',     \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 64, 64, 32)   18464       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 64, 64, 32)   0           ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 64, 64, 32)   9248        ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 128, 128, 16  2064       ['conv2d_15[0][0]']              \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 128, 128, 32  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                )                                 'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 128, 128, 16  4624        ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128, 128, 16  0           ['conv2d_16[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 128, 128, 16  2320        ['dropout_8[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 128, 128, 5)  85          ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,940,885\n",
      "Trainable params: 1,940,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = simple_unet_model(n_classes, patch_size, patch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m cb \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      2\u001b[0m                    patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m      3\u001b[0m                    restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m                    mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mened\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\mened\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "cb = EarlyStopping(monitor='val_loss',\n",
    "                   patience=2,\n",
    "                   restore_best_weights='True',\n",
    "                   mode='min')\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=16,\n",
    "                    epochs=15,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc, f1, iou = model.evaluate(X_test, y_test, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot(history, \"U-net model loss\")\n",
    "accuracy_plot(history, \"U-net model accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_test = images_test[15]\n",
    "image_to_test, _, _, _, _ = roi_image(image_to_test)\n",
    "image_to_test = padder(image_to_test, patch_size)\n",
    "\n",
    "image_to_test = cv2.resize(image_to_test, (0, 0), fx=scaling_factor, fy=scaling_factor)\n",
    "\n",
    "patches = patchify(image_to_test, (patch_size, patch_size), step=patch_size)\n",
    "\n",
    "print(patches.shape)\n",
    "\n",
    "i = patches.shape[0]\n",
    "j = patches.shape[1]\n",
    "\n",
    "patches = patches.reshape(-1, patch_size, patch_size, 1)\n",
    "\n",
    "preds = model.predict(patches/255)\n",
    "preds_argmax = np.argmax(preds, axis=-1)\n",
    "\n",
    "preds_reshaped = preds_argmax.reshape(i, j, patch_size, patch_size)\n",
    "\n",
    "predicted_mask = unpatchify(preds_reshaped, (i*patch_size, j*patch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_to_test, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predicted_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
