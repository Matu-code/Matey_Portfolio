{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from textblob import TextBlob\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'  \n",
    "\n",
    "    clean_text = re.sub(pattern, '', text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.read_csv('data/emotion_data_merged.csv')\n",
    "kaggle_data = pd.read_csv('data/simplified_emotions_f.csv')\n",
    "test = pd.read_csv('data/test.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data['Sentences'] = main_data['Sentences'].apply(remove_special_characters)\n",
    "kaggle_data['Sentences'] = kaggle_data['Sentences'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def POStag_extracting(data, column='Sentence'):\n",
    "\n",
    "    verbs_per_sentence = []\n",
    "    adjectives_per_sentence = []\n",
    "\n",
    "    for sent in nlp.pipe(data[column]):\n",
    "        if sent.has_annotation('POS'):\n",
    "            verbs = [word.text for word in sent if word.pos_ == 'VERB']\n",
    "            adjectives = [word.text for word in sent if word.pos_ == 'ADJ']\n",
    "\n",
    "            verbs_per_sentence.append(verbs)\n",
    "            adjectives_per_sentence.append(adjectives)\n",
    "\n",
    "    data['Verbs'] = verbs_per_sentence\n",
    "    data['Adjectives'] = adjectives_per_sentence\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_data = POStag_extracting(kaggle_data)\n",
    "main_data = POStag_extracting(main_data)\n",
    "test = POStag_extracting(test, 'sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_data[['Verbs', 'Adjectives']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data[['Verbs', 'Adjectives']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['Verbs', 'Adjectives']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    \n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif analysis.sentiment.polarity < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_data['sentiment'] = kaggle_data['Sentences'].apply(analyze_sentiment)\n",
    "main_data['sentiment'] = main_data['Sentences'].apply(analyze_sentiment)\n",
    "test['sentiment'] = test['Sentences'].apply(analyze_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"C:\\Users\\mened\\OneDrive\\Desktop\\GoogleNews-vectors-negative300.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embeddings(sentence, model):\n",
    "    words = word_tokenize(sentence.lower())\n",
    "    # Initialize an empty vector\n",
    "    total_vector = np.zeros(model.vector_size)\n",
    "    for word in words:\n",
    "        if word in model.wv:\n",
    "            total_vector += model.wv[word]\n",
    "    # Average the vectors\n",
    "    if len(words) > 0:\n",
    "        total_vector /= len(words)\n",
    "    return total_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embeddings_to_dataset(model, dataset, column):\n",
    "    embeddings = []\n",
    "    for sentence in dataset[column]:\n",
    "        embeddings.append(word_embeddings(sentence, model))\n",
    "    dataset['embedding'] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_embeddings_to_dataset(word2vec_model, kaggle_data, 'Sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_embeddings_to_dataset(word2vec_model, main_data, 'Sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_embeddings_to_dataset(word2vec_model, test, 'sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_data['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['embedding']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
