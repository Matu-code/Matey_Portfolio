{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import gensim\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/emotion_data_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Sofabsports thank you for following me back. ...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433308</th>\n",
       "      <td>A reminder that &gt;![NAME]!&lt; unironically likes ...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433309</th>\n",
       "      <td>Hopefully they got a chance to see [NAME].</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433310</th>\n",
       "      <td>Perhaps you are right and the stereotype that ...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433311</th>\n",
       "      <td>I just called the Capitol Police. They are not...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433312</th>\n",
       "      <td>Couldnt find this one in google, where abouts ...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433313 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentences   Emotions\n",
       "0       Dorian Gray with Rainbow Scarf #LoveWins (from...  happiness\n",
       "1       @SelectShowcase @Tate_StIves ... Replace with ...  happiness\n",
       "2       @Sofabsports thank you for following me back. ...  happiness\n",
       "3       @britishmuseum @TudorHistory What a beautiful ...  happiness\n",
       "4       @NationalGallery @ThePoldarkian I have always ...  happiness\n",
       "...                                                   ...        ...\n",
       "433308  A reminder that >![NAME]!< unironically likes ...  happiness\n",
       "433309         Hopefully they got a chance to see [NAME].  happiness\n",
       "433310  Perhaps you are right and the stereotype that ...    disgust\n",
       "433311  I just called the Capitol Police. They are not...      anger\n",
       "433312  Couldnt find this one in google, where abouts ...    disgust\n",
       "\n",
       "[433313 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [dorian, gray, with, rainbow, scarf, lovewins,...\n",
       "1         [selectshowcase, tate_stives, replace, with, y...\n",
       "2         [sofabsports, thank, you, for, following, me, ...\n",
       "3         [britishmuseum, tudorhistory, what, beautiful,...\n",
       "4         [nationalgallery, thepoldarkian, have, always,...\n",
       "                                ...                        \n",
       "433308    [reminder, that, name, unironically, likes, th...\n",
       "433309        [hopefully, they, got, chance, to, see, name]\n",
       "433310    [perhaps, you, are, right, and, the, stereotyp...\n",
       "433311    [just, called, the, capitol, police, they, are...\n",
       "433312    [couldnt, find, this, one, in, google, where, ...\n",
       "Name: Sentences, Length: 433313, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = data.Sentences.apply(gensim.utils.simple_preprocess)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(sentences, progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26454205, 36029725)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(sentences, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embeddings(sentence):\n",
    "    words = word_tokenize(sentence.lower())\n",
    "    # Initialize an empty vector\n",
    "    total_vector = np.zeros(model.vector_size)\n",
    "    for word in words:\n",
    "        if word in model.wv:\n",
    "            total_vector += model.wv[word]\n",
    "    # Average the vectors\n",
    "    if len(words) > 0:\n",
    "        total_vector /= len(words)\n",
    "    return total_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embeddings_to_dataset(dataset, column):\n",
    "    embeddings = []\n",
    "    for sentence in dataset[column]:\n",
    "        embeddings.append(word_embeddings(sentence))\n",
    "    dataset['embedding'] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_embeddings_to_dataset(data, 'Sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Emotions</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[-0.2156420982339316, -0.39359256914920276, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[-0.24448896430078007, -0.17164118366227263, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Sofabsports thank you for following me back. ...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[-0.4075755175823967, 0.047608294000383466, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[0.04615092230960727, 0.3647947927054606, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[-0.005486067723144184, 0.2538980638439005, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433308</th>\n",
       "      <td>A reminder that &gt;![NAME]!&lt; unironically likes ...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[-0.24532882845960557, -0.06553940010053338, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433309</th>\n",
       "      <td>Hopefully they got a chance to see [NAME].</td>\n",
       "      <td>happiness</td>\n",
       "      <td>[-0.0942016565664248, -0.7372868054292419, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433310</th>\n",
       "      <td>Perhaps you are right and the stereotype that ...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>[0.08553577214479446, -0.11938284923830493, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433311</th>\n",
       "      <td>I just called the Capitol Police. They are not...</td>\n",
       "      <td>anger</td>\n",
       "      <td>[-0.31818711827509105, -0.4231173995261391, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433312</th>\n",
       "      <td>Couldnt find this one in google, where abouts ...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>[-0.6493245594513913, -0.474462054669857, 0.08...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433313 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentences   Emotions  \\\n",
       "0       Dorian Gray with Rainbow Scarf #LoveWins (from...  happiness   \n",
       "1       @SelectShowcase @Tate_StIves ... Replace with ...  happiness   \n",
       "2       @Sofabsports thank you for following me back. ...  happiness   \n",
       "3       @britishmuseum @TudorHistory What a beautiful ...  happiness   \n",
       "4       @NationalGallery @ThePoldarkian I have always ...  happiness   \n",
       "...                                                   ...        ...   \n",
       "433308  A reminder that >![NAME]!< unironically likes ...  happiness   \n",
       "433309         Hopefully they got a chance to see [NAME].  happiness   \n",
       "433310  Perhaps you are right and the stereotype that ...    disgust   \n",
       "433311  I just called the Capitol Police. They are not...      anger   \n",
       "433312  Couldnt find this one in google, where abouts ...    disgust   \n",
       "\n",
       "                                                embedding  \n",
       "0       [-0.2156420982339316, -0.39359256914920276, -0...  \n",
       "1       [-0.24448896430078007, -0.17164118366227263, -...  \n",
       "2       [-0.4075755175823967, 0.047608294000383466, -0...  \n",
       "3       [0.04615092230960727, 0.3647947927054606, -0.2...  \n",
       "4       [-0.005486067723144184, 0.2538980638439005, 0....  \n",
       "...                                                   ...  \n",
       "433308  [-0.24532882845960557, -0.06553940010053338, -...  \n",
       "433309  [-0.0942016565664248, -0.7372868054292419, -0....  \n",
       "433310  [0.08553577214479446, -0.11938284923830493, 0....  \n",
       "433311  [-0.31818711827509105, -0.4231173995261391, -0...  \n",
       "433312  [-0.6493245594513913, -0.474462054669857, 0.08...  \n",
       "\n",
       "[433313 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
